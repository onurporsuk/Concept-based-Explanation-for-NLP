{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059b90ff-00c5-40fb-870a-1c7d48253822",
   "metadata": {},
   "source": [
    "# Small Code Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1867432-2112-47a4-a925-1ec7c0188dde",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Huggingface Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8b28c3d-cef4-4d50-a8bd-3a7a59f3949e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "# batch_size_cockatiel = 64\n",
    "\n",
    "# n_concepts = 20\n",
    "# #n_reviews = 20000\n",
    "# n_excerpts = 50000\n",
    "# n_reviews_for_excerpts = 100000\n",
    "\n",
    "# positive_class = 1\n",
    "# negative_class = 0\n",
    "\n",
    "# output_names = ['negative', 'positive']\n",
    "# parent_path = \"data/huggingface_test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324ca18-7a71-4911-b249-901f8831f4ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5ef05-44e4-4d06-8ad7-c4e98e427cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def clear_gpu_memory():\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def predict(model, tokenizer, samples, device):\n",
    "    \n",
    "    samples = [[sample[0], 1 if sample[1] == 'positive' else 0] for sample in samples]\n",
    "\n",
    "    r = np.array(list(map(lambda z: z[0], samples)))\n",
    "    tokenized_samples = tokenize(r, tokenizer, device)\n",
    "    preds = model(**tokenized_samples)\n",
    "\n",
    "    # Extract texts and raw prediction scores\n",
    "    raw_scores = preds.cpu().detach().numpy()\n",
    "\n",
    "    # Extract predicted labels\n",
    "    predictions = np.argmax(raw_scores, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    true_labels = [int(sample[1]) for sample in samples]\n",
    "    \n",
    "    return predictions, true_labels\n",
    "\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", round(accuracy, 2))\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    metrics = classification_report(y_test, y_pred)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(metrics)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e53394-8b8e-450e-b515-5fa8b2f14b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, samples, device):\n",
    "    \n",
    "    samples = [[sample[0], 1 if sample[1] == 'positive' else 0] for sample in samples]\n",
    "\n",
    "    r = np.array(list(map(lambda z: z[0], samples)))\n",
    "\n",
    "    tokenized_samples = tokenize(r, tokenizer, device)\n",
    "\n",
    "    preds = model(**tokenized_samples)\n",
    "\n",
    "    # Extract texts and raw prediction scores\n",
    "    texts = r\n",
    "    raw_scores = preds.cpu().detach().numpy()\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = torch.softmax(torch.tensor(raw_scores), dim=1)\n",
    "\n",
    "    # positive_probabilities = probabilities[:, 1]  # Probability for the positive class\n",
    "    # negative_probabilities = probabilities[:, 0]  # Probability for the negative class\n",
    "\n",
    "    # Extract predicted labels\n",
    "    predictions = np.argmax(raw_scores, axis=1)\n",
    "    \n",
    "    # result = {\n",
    "    #     'Text': texts,\n",
    "    #     'Predictions': predictions,\n",
    "    #     'Positive Probability': positive_probabilities,\n",
    "    #     'Negative Probability': negative_probabilities,\n",
    "    # }\n",
    "\n",
    "    # Calculate accuracy\n",
    "    true_labels = [int(sample[1]) for sample in samples]\n",
    "    \n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b8cae-a64b-4922-b56f-88c8df6e9f83",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Making Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764660b-203c-4e3f-9bd8-4368a92ae73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions on some samples\n",
    "# y_pred, labels = batch_predict(model.forward, tokenizer, data_np[:1000], batch_size, device)\n",
    "\n",
    "# # Compute the activations on which to apply the NMF\n",
    "# features, labels = batch_predict(model.features, tokenizer, data_np[:1000], batch_size, device)\n",
    "\n",
    "# # Go from these activations to the final prediction\n",
    "# y_pred_bis = model.end_model(features)\n",
    "\n",
    "# print(\"\\nAccuracy for classic model        :\", torch.mean((torch.argmax(y_pred, -1) == labels.to(device)).float()))\n",
    "# print(\"Accuracy for model in 'two parts' :\", torch.mean((torch.argmax(y_pred_bis, -1) == labels.to(device)).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4b51557-bb0d-42be-bba0-923c3e7a66b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11926   299]\n",
      " [  546 12226]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97     12225\n",
      "         1.0       0.98      0.96      0.97     12772\n",
      "\n",
      "    accuracy                           0.97     24997\n",
      "   macro avg       0.97      0.97      0.97     24997\n",
      "weighted avg       0.97      0.97      0.97     24997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions, labels = predict(model, tokenizer, data_np[25000:], device)\n",
    "# evaluate(predictions, labels)\n",
    "# clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bfba0d1-ccad-4605-85e0-a97b3e01fb50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 909   33]\n",
      " [  38 1020]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       942\n",
      "         1.0       0.97      0.96      0.97      1058\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions, labels = predict(model, tokenizer, data_np[25000:27000], device)\n",
    "# evaluate(predictions, labels)\n",
    "# clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c52935-84de-4b13-9e48-9ab591638e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
